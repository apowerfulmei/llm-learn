{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 逻辑回归\n",
    "\n",
    "## 🧠 一、逻辑回归到底是什么？\n",
    "\n",
    "逻辑回归是一种用于 **二分类**（也可以扩展到多分类）的问题的 **监督学习模型**。尽管名字叫“回归”，但它其实是一个**分类算法**。\n",
    "\n",
    "> **用途：** 用来预测一个样本属于某个类别的概率，例如：\n",
    "> - 邮件是否是垃圾邮件？\n",
    "> - 一个人是否会点击广告？\n",
    "> - 病人是否患病？\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ 二、逻辑回归的数学原理\n",
    "\n",
    "### ✅ 1. 假设函数（sigmoid 函数）\n",
    "\n",
    "逻辑回归不是直接预测 $ y $，而是预测它为正类的概率：\n",
    "\n",
    "$$\n",
    "P(y=1 \\mid x) = \\sigma(z) = \\frac{1}{1 + e^{-z}}, \\quad z = \\theta^T x\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $ x $：特征向量\n",
    "- $ \\theta $：模型参数\n",
    "- $ \\sigma(z) $：**sigmoid 函数**，把任意实数压缩到 (0,1) 区间\n",
    "\n",
    "> 直观理解：sigmoid 像一个 S 型函数，可以把线性模型输出转换成“概率感”。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. 决策边界\n",
    "\n",
    "预测时，如果：\n",
    "\n",
    "$$\n",
    "P(y=1 \\mid x) \\geq 0.5 \\Rightarrow \\text{预测为正类}\n",
    "$$\n",
    "$$\n",
    "P(y=1 \\mid x) < 0.5 \\Rightarrow \\text{预测为负类}\n",
    "$$\n",
    "\n",
    "所以 $ \\theta^T x = 0 $ 就是分类的“分界线”（或者超平面） → **决策边界**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 3. 损失函数（交叉熵）\n",
    "\n",
    "逻辑回归的损失函数不是 MSE，而是**对数似然损失**（也叫交叉熵损失）：\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
    "$$\n",
    "\n",
    "其中：\n",
    "\n",
    "- $ \\hat{y}^{(i)} = \\sigma(\\theta^T x^{(i)}) $\n",
    "- 目标是最小化 $ J(\\theta) $\n",
    "\n",
    "这个函数是 **凸函数**，所以可以用梯度下降求解。\n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 三、逻辑回归训练过程\n",
    "\n",
    "1. 初始化参数 $ \\theta $\n",
    "2. 通过训练集计算预测值 $ \\hat{y} $\n",
    "3. 使用交叉熵计算损失\n",
    "4. 使用梯度下降（或其他优化方法）更新参数\n",
    "5. 重复迭代直到收敛\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 四、逻辑回归的优点\n",
    "\n",
    "✅ 简单、可解释性强\n",
    "✅ 训练速度快\n",
    "✅ 可以输出概率\n",
    "✅ 对线性可分数据效果好\n",
    "✅ 可扩展到多分类（One-vs-Rest）\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 五、常见限制\n",
    "\n",
    "❌ 无法处理非线性决策边界（除非加特征变换）\n",
    "❌ 对离群值敏感\n",
    "❌ 需要特征标准化以加速收敛\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 如果用一句话总结逻辑回归：\n",
    "\n",
    "> **逻辑回归是一种使用 sigmoid 函数将线性模型输出映射为概率的二分类模型，训练过程使用交叉熵损失，通过梯度下降拟合最优参数。**"
   ],
   "id": "3d29e5e21bbb54fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
