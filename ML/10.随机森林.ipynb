{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 随机森林\n",
    "\n",
    "随机森林（Random Forest）是一种 **集成学习（Ensemble Learning）** 方法，主要用于分类和回归问题。它是基于 **决策树（Decision Tree）** 构建的，通过构建多个决策树并将其结果进行集成，来提高预测准确率和模型稳定性。\n",
    "\n",
    "---\n",
    "\n",
    "## 一、核心思想\n",
    "\n",
    "随机森林的核心思想可以简述为：\n",
    "\n",
    "> **“构建多棵决策树，然后让它们投票表决（分类）或平均（回归）结果。”**\n",
    "\n",
    "---\n",
    "\n",
    "## 二、构造流程\n",
    "\n",
    "随机森林的构建流程如下：\n",
    "\n",
    "### 步骤 1：数据集的随机抽样（Bootstrap）\n",
    "- 给定一个训练集 $ D $（含 $ n $ 个样本），从中**有放回地**随机抽取 $ n $ 个样本，构建一个**子训练集**。\n",
    "- 重复该过程 $ k $ 次，生成 $ k $ 个子训练集，每个用于训练一棵决策树。\n",
    "- 这种方法叫 **Bootstrap Aggregating（简称 Bagging）**。\n",
    "\n",
    "### 步骤 2：构建每棵决策树\n",
    "- 在构建树的每个节点时，不再使用所有特征来选择最优划分，而是从所有特征中**随机选择 $ m $ 个特征**（通常 $ m < M $，M 为全部特征数），在这些特征中选择最优划分。\n",
    "- 这种做法引入了特征层面的随机性，进一步提高模型的泛化能力。\n",
    "\n",
    "### 步骤 3：集成多个树的结果\n",
    "- **分类任务：** 每棵树进行投票，最终结果是投票最多的类别（多数表决）。\n",
    "- **回归任务：** 所有树的输出取平均值。\n",
    "\n",
    "---\n",
    "\n",
    "## 三、随机森林的优点\n",
    "\n",
    "| 优点       | 说明                             |\n",
    "|----------|--------------------------------|\n",
    "| 高精度      | 由于是集成多个弱模型（决策树），整体性能通常优于单个模型   |\n",
    "| 抗过拟合     | 随机性+集成方式使得模型不容易过拟合             |\n",
    "| 可处理高维数据  | 对特征维度不敏感，不需要特征选择               |\n",
    "| 可评估特征重要性 | 可通过特征在树中的使用频率、节点分裂贡献等方式衡量特征重要性 |\n",
    "| 可并行      | 每棵树可以独立训练，非常适合并行计算             |\n",
    "\n",
    "---\n",
    "\n",
    "## 四、随机森林中的重要概念\n",
    "\n",
    "### 1. OOB（Out-of-Bag）误差\n",
    "- 每个子训练集是从原始数据有放回地采样的，因此大约有 **1/3 的样本未被选中**，这些叫做“袋外样本”。\n",
    "- 可以用袋外样本来**评估模型性能**，不需要额外划分验证集。\n",
    "\n",
    "### 2. 特征重要性（Feature Importance）\n",
    "- 常见计算方法：\n",
    "  - **基于 Gini 不纯度的下降**\n",
    "  - **基于信息增益的贡献**\n",
    "  - **Permutation Importance（置换特征后的性能下降）**\n",
    "\n",
    "---\n",
    "\n",
    "## 五、与单棵决策树的对比\n",
    "\n",
    "| 项目      | 决策树     | 随机森林        |\n",
    "|---------|---------|-------------|\n",
    "| 是否容易过拟合 | 是       | 否（通过集成降低）   |\n",
    "| 稳定性     | 较差      | 高（对数据波动不敏感） |\n",
    "| 可解释性    | 强（可可视化） | 相对较弱（模型复杂）  |\n",
    "| 准确率     | 一般      | 通常更高        |\n",
    "\n",
    "---\n",
    "\n",
    "## 六、超参数调节\n",
    "\n",
    "在使用随机森林时，有几个关键的超参数：\n",
    "\n",
    "| 参数                  | 说明                |\n",
    "|---------------------|-------------------|\n",
    "| `n_estimators`      | 决策树的数量，越多越稳定但训练更慢 |\n",
    "| `max_features`      | 每个节点随机选取的特征数      |\n",
    "| `max_depth`         | 每棵树的最大深度，防止过拟合    |\n",
    "| `min_samples_split` | 一个节点再分裂所需的最小样本数   |\n",
    "| `bootstrap`         | 是否使用有放回采样（True）   |"
   ],
   "id": "d34567356754df01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T03:00:19.149229Z",
     "start_time": "2025-04-30T03:00:14.739630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# 划分训练/测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 创建模型\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 测试精度\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ],
   "id": "e7aa45606717f7a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
