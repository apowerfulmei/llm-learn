# 标准方程的推导过程

$$
\theta = (X^T X)^{-1} X^T y
$$

这个公式是怎么来的。你只要能理解平方、加法、导数是干什么的，就可以看懂！

---

## 🧠 问题背景：我们要干嘛？

我们做线性回归，目标是：

- 输入数据：特征矩阵 $ X $
- 目标值：输出向量 $ y $
- 要找一组参数 $ \theta $，使得：
  
  $$
  \hat{y} = X\theta
  $$
  
  尽可能接近 $ y $

---

## 🎯 我们的目标：

让预测值 $ \hat{y} = X\theta $ 和实际值 $ y $ 差得最小。

用“**平方误差**”来衡量差距，写成损失函数（也叫代价函数）：

$$
J(\theta) = \| X\theta - y \|^2
$$

这个符号是“向量的平方长度”，它的本质是：

$$
J(\theta) = (X\theta - y)^T (X\theta - y)
$$

就是说：先算预测值和真实值的差，平方并加起来。

---

> 我们来非常通俗地解释这句话，哪怕你对线性代数不太熟也没关系。我们逐个词来讲：
> ## 🌟 原式：
> $$
J(\theta) = \| X\theta - y \|^2
$$
> 这个符号是什么意思？先看核心部分：
> 
> ### ✅ $\| \cdot \|$ 是向量的“长度”（也叫范数）
> 所以 $\| X\theta - y \|$ 表示：
> 预测值 $X\theta$ 和真实值 $y$ 之间差距的“整体距离”
> 再加个平方：
$$
\| X\theta - y \|^2
$$
> 意思就是这个“距离”的平方，也就是**所有误差的平方加总**
> ---
> ## ✅ 换种写法：向量长度的平方可以写成内积（点乘）
> 数学上有个结论：
$$
\| a \|^2 = a^T a
$$
> 这就好比：
$$
\text{向量的平方长度} = \text{它自己和自己的点积}
$$
> ---
> ## ✅ 应用到这个问题上：
> 设：
$$
a = X\theta - y
$$
> 所以：
$$
J(\theta) = \| X\theta - y \|^2 = (X\theta - y)^T (X\theta - y)
$$
> 这就是那句话的意思：
$$
J(\theta) = \| X\theta - y \|^2 = (X\theta - y)^T (X\theta - y)
$$
> 它的意思是：
> - “误差向量的平方长度”  
> = “误差向量和自己的点积”  
> = “所有样本误差的平方和”
> ---
> ## 📌 举个小例子（具体数字！）
> 假设：
$$
X\theta = 
\begin{bmatrix}
2 \\
4 \\
6
\end{bmatrix}
,\quad
y = 
\begin{bmatrix}
1 \\
5 \\
4
\end{bmatrix}
$$
> 那么误差是：
$$
X\theta - y = 
\begin{bmatrix}
2 - 1 \\
4 - 5 \\
6 - 4
\end{bmatrix}
=
\begin{bmatrix}
1 \\
-1 \\
2
\end{bmatrix}
$$
> 这个向量的平方长度：
$$
\| X\theta - y \|^2 = 1^2 + (-1)^2 + 2^2 = 1 + 1 + 4 = 6
$$
> 换成点乘写法：
$$
(X\theta - y)^T (X\theta - y)
=
\begin{bmatrix}
1 & -1 & 2
\end{bmatrix}
\cdot
\begin{bmatrix}
1 \\
-1 \\
2
\end{bmatrix}
= 1 + 1 + 4 = 6
$$
> ✅ 结果完全一样！
> ---
> ## 🧠 总结这句话的意思：
> 向量的平方长度（$\| a \|^2$）其实就是向量自己点乘自己（$a^T a$），所以我们把平方误差写成 $(X\theta - y)^T (X\theta - y)$ 是完全一样的，只是换了一种“更方便计算”的写法。
---

## 🔍 我们的任务：

**求一组 $ \theta $，使得 $ J(\theta) $ 最小。**  
这在数学上叫“最小化一个函数”，我们要对它 **求导**，再让导数等于 0。

---

## ✅ 第一步：写出损失函数

我们先写出误差函数：

$$
J(\theta) = (X\theta - y)^T (X\theta - y)
$$

这个式子是个数值，不是向量了。

---

## ✅ 第二步：展开这个式子

用乘法公式展开：

$$
J(\theta) = (X\theta)^T (X\theta) - 2y^T (X\theta) + y^T y
$$

为什么这样展开？其实你可以把 $ (a - b)^2 $ 看成：
$$
a^T a - 2a^T b + b^T b
$$
在这里 $ a = X\theta $，$ b = y $

我们得到的式子变成：

$$
J(\theta) = \theta^T X^T X \theta - 2 \theta^T X^T y + y^T y
$$

> 注意：这是标量（实数），不是矩阵了！

---

## ✅ 第三步：对 $ \theta $ 求导

我们要求最小值 → 对 $ \theta $ 求导 → 导数设为 0。

### 我们用的导数规则（简化版）：

- $ \frac{d}{d\theta}(\theta^T A \theta) = 2A\theta $
- $ \frac{d}{d\theta}(b^T \theta) = b $

对每一项分别求导：

1. $ \frac{d}{d\theta}(\theta^T X^T X \theta) = 2X^T X \theta $

2. $ \frac{d}{d\theta}(-2 \theta^T X^T y) = -2 X^T y $

3. 最后一项 $ y^T y $ 与 $ \theta $ 无关，导数是 0

把这三项加起来：

$$
\nabla_\theta J(\theta) = 2X^T X \theta - 2X^T y
$$

---

## ✅ 第四步：令导数为 0（最小值点）

我们令导数为 0：

$$
2X^T X \theta - 2X^T y = 0
$$

两边同时除以 2：

$$
X^T X \theta = X^T y
$$

这就是我们要解的“标准方程”！

---

## ✅ 第五步：解这个方程

我们把 $ X^T X $ 移到等式右边：

$$
\theta = (X^T X)^{-1} X^T y
$$

这就是我们最终的解：**最小二乘法的闭式解（closed-form solution）**！

---

## 🧾 总结一遍推导过程：

1. 目标是最小化误差平方和：

   $$
   J(\theta) = \| X\theta - y \|^2
   $$

2. 展开这个式子：

   $$
   J(\theta) = \theta^T X^T X \theta - 2 \theta^T X^T y + y^T y
   $$

3. 对 $ \theta $ 求导，令导数为 0：

   $$
   X^T X \theta = X^T y
   $$

4. 解出 $ \theta $：

   $$
   \theta = (X^T X)^{-1} X^T y
   $$

---

## 💡 形象理解一句话总结：

我们在做的事情就像是在玩“拼图”：  
找到最合适的一组拼图块 $ \theta $，拼出一条线，使它尽可能贴合所有的点。

---

如果你希望我配一张图来说明“误差平方最小化”的几何意义，或者再做一次“从矩阵角度逐步展开推导”，也可以直接说！我可以可视化给你看～